{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zal-eun/spanish-translation-model/blob/main/spanish_translation_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L7wcN_7ObB00",
      "metadata": {
        "id": "L7wcN_7ObB00"
      },
      "source": [
        "라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a40647a",
      "metadata": {
        "id": "9a40647a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import urllib3\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gOaWuWnqbEzO",
      "metadata": {
        "id": "gOaWuWnqbEzO"
      },
      "source": [
        "스페인어 텍스트 샘플"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fFcTejTokM_9",
      "metadata": {
        "id": "fFcTejTokM_9"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f4babe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88f4babe",
        "outputId": "bb1273f1-ac62-49d4-8771-498245a952fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "139013"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines =pd.read_csv(\"C:\\\\Users\\\\82105\\\\Desktop\\\\spa.txt\",names=['eng','spa','lic'],sep='\\t')\n",
        "del lines['lic']\n",
        "#lines = lines[:100]\n",
        "len(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wAOAsCJQxRvR",
      "metadata": {
        "id": "wAOAsCJQxRvR"
      },
      "source": [
        "총 139013 개의 샘플 중 60000개만 저장한다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0390737",
      "metadata": {
        "id": "e0390737"
      },
      "outputs": [],
      "source": [
        "lines = lines.loc[:,'eng':'spa']\n",
        "lines = lines[0:400000]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jA-nhPb9xkhx",
      "metadata": {
        "id": "jA-nhPb9xkhx"
      },
      "source": [
        "문장의 시작과 끝을 슬라이싱 하기 위해서 \\t와 \\n을 추가한다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c3d69cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "4c3d69cb",
        "outputId": "6a85972f-707f-4c8b-e9a9-ce34187a84b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>spa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19400</th>\n",
              "      <td>Control yourselves.</td>\n",
              "      <td>\\t \\t Controlaos. \\n \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       eng                      spa\n",
              "19400  Control yourselves.  \\t \\t Controlaos. \\n \\n"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines.spa = lines.spa.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "lines.sample(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dJDksqxXyYfi",
      "metadata": {
        "id": "dJDksqxXyYfi"
      },
      "source": [
        "알파벳 기준의 단어집합(vocab)을 형성하기 위하여 각 영어 리스트와 상응하는 스페인어 리스트 문자에 있는 글자를 읽어 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae494d0",
      "metadata": {
        "id": "8ae494d0"
      },
      "outputs": [],
      "source": [
        "eng_vocab = set()\n",
        "for line in lines.eng: \n",
        "    for char in line: \n",
        "        eng_vocab.add(char)\n",
        "\n",
        "spa_vocab = set()\n",
        "for line in lines.spa:\n",
        "    for char in line:\n",
        "        spa_vocab.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1c7990b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1c7990b",
        "outputId": "76231a11-e908-4ee8-963d-ef0e0342c180"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "english 문장의 단어 집합 수: 82\n",
            "spanish 문장의 단어 집합 수: 103\n"
          ]
        }
      ],
      "source": [
        "eng_vocab_size = len(eng_vocab)+1\n",
        "spa_vocab_size = len(spa_vocab)+1\n",
        "print('english 문장의 단어 집합 수:',eng_vocab_size)\n",
        "print('spanish 문장의 단어 집합 수:',spa_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TZGlKhl3zD9A",
      "metadata": {
        "id": "TZGlKhl3zD9A"
      },
      "source": [
        "데이터 범위 내에서 영어는 82개의 문자, 스페인어는 총 103의 문자가 존재함을 알 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "532c7bdd",
      "metadata": {
        "id": "532c7bdd"
      },
      "outputs": [],
      "source": [
        "eng_vocab = sorted(list(eng_vocab))\n",
        "spa_vocab = sorted(list(spa_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cXAREbiezyp-",
      "metadata": {
        "id": "cXAREbiezyp-"
      },
      "source": [
        ":각 번호를 할당시켜 정렬하는 enumerate를 통해 인덱스를 부여한다.<br>\n",
        "인덱스 첫 값이 0인 점에서 +1을 해준다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29390bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f29390bd",
        "outputId": "14c88d3f-0387-4143-9444-ce5e9d845623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, '/': 10, '0': 11, '1': 12, '2': 13, '3': 14, '4': 15, '5': 16, '6': 17, '7': 18, '8': 19, '9': 20, ':': 21, ';': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '\\xa0': 76, '°': 77, 'é': 78, '‘': 79, '’': 80, '€': 81}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, \"'\": 8, '(': 9, ')': 10, '+': 11, ',': 12, '-': 13, '.': 14, '/': 15, '0': 16, '1': 17, '2': 18, '3': 19, '4': 20, '5': 21, '6': 22, '7': 23, '8': 24, '9': 25, ':': 26, ';': 27, '?': 28, 'A': 29, 'B': 30, 'C': 31, 'D': 32, 'E': 33, 'F': 34, 'G': 35, 'H': 36, 'I': 37, 'J': 38, 'K': 39, 'L': 40, 'M': 41, 'N': 42, 'O': 43, 'P': 44, 'Q': 45, 'R': 46, 'S': 47, 'T': 48, 'U': 49, 'V': 50, 'W': 51, 'X': 52, 'Y': 53, 'Z': 54, 'a': 55, 'b': 56, 'c': 57, 'd': 58, 'e': 59, 'f': 60, 'g': 61, 'h': 62, 'i': 63, 'j': 64, 'k': 65, 'l': 66, 'm': 67, 'n': 68, 'o': 69, 'p': 70, 'q': 71, 'r': 72, 's': 73, 't': 74, 'u': 75, 'v': 76, 'w': 77, 'x': 78, 'y': 79, 'z': 80, '¡': 81, '«': 82, '°': 83, 'º': 84, '»': 85, '¿': 86, 'Á': 87, 'É': 88, 'Ó': 89, 'Ú': 90, 'á': 91, 'é': 92, 'í': 93, 'ñ': 94, 'ó': 95, 'ú': 96, 'ü': 97, 'ś': 98, 'с': 99, '\\u200b': 100, '—': 101, '€': 102}\n"
          ]
        }
      ],
      "source": [
        "eng_to_index = dict([(word, i+1) for i, word in enumerate(eng_vocab)])\n",
        "spa_to_index = dict([(word, i+1) for i, word in enumerate(spa_vocab)])\n",
        "print(eng_to_index)\n",
        "print(spa_to_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gyykpXlw0dDq",
      "metadata": {
        "id": "gyykpXlw0dDq"
      },
      "source": [
        "영어에 대한 정수 인코딩 진행(line에 있는 각 문자 char에 대해 정수로 변환시킴)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b96039b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b96039b",
        "outputId": "ddcd23a5-e4fc-4059-ca35-733d6b26fcf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "영어 문장의 정수 인코딩 : [[30, 64, 9], [30, 64, 9], [30, 64, 9], [30, 64, 9], [31, 58, 9]]\n"
          ]
        }
      ],
      "source": [
        "encoder_input = []\n",
        "\n",
        "\n",
        "for line in lines.eng:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(eng_to_index[char])\n",
        "  encoder_input.append(encoded_line)\n",
        "print('영어 문장의 정수 인코딩 :',encoder_input[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oQGS-EF408C5",
      "metadata": {
        "id": "oQGS-EF408C5"
      },
      "source": [
        "tar(스페인어)에 대한 정수 디코딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7332d50",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7332d50",
        "outputId": "397cdc78-dc61-4e8e-f1da-9c539fe8a478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "스페인어 문장의 정수 인코딩 : [[1, 3, 1, 3, 50, 59, 14, 3, 2, 3, 2], [1, 3, 1, 3, 50, 59, 74, 59, 14, 3, 2, 3, 2], [1, 3, 1, 3, 50, 55, 79, 55, 14, 3, 2, 3, 2], [1, 3, 1, 3, 50, 91, 79, 55, 73, 59, 14, 3, 2, 3, 2], [1, 3, 1, 3, 36, 69, 66, 55, 14, 3, 2, 3, 2]]\n"
          ]
        }
      ],
      "source": [
        "decoder_input = []\n",
        "for line in lines.spa:\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    encoded_line.append(spa_to_index[char])\n",
        "  decoder_input.append(encoded_line)\n",
        "print('스페인어 문장의 정수 인코딩 :',decoder_input[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0AbX41rL7U1k",
      "metadata": {
        "id": "0AbX41rL7U1k"
      },
      "source": [
        "영어문장으로부터 스페인어 문장에 targeting한 값이  올바르게 수행되었는지 확인하기 위해서 실제값을 함께 정수 인코딩 한다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e45f59c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e45f59c",
        "outputId": "1d69e616-c02e-442a-864b-45b23029f6ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "실제값 정수 인코딩 : [[3, 1, 3, 50, 59, 14, 3, 2, 3, 2], [3, 1, 3, 50, 59, 74, 59, 14, 3, 2, 3, 2], [3, 1, 3, 50, 55, 79, 55, 14, 3, 2, 3, 2], [3, 1, 3, 50, 91, 79, 55, 73, 59, 14, 3, 2, 3, 2], [3, 1, 3, 36, 69, 66, 55, 14, 3, 2, 3, 2]]\n"
          ]
        }
      ],
      "source": [
        "decoder_target = []\n",
        "for line in lines.spa:\n",
        "  timestep = 0\n",
        "  encoded_line = []\n",
        "  for char in line:\n",
        "    if timestep > 0:\n",
        "      encoded_line.append(spa_to_index[char])\n",
        "    timestep = timestep + 1\n",
        "  decoder_target.append(encoded_line)\n",
        "print('실제값 정수 인코딩 :',decoder_target[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MXN3oY8oX22F",
      "metadata": {
        "id": "MXN3oY8oX22F"
      },
      "source": [
        "padding 작업을 위한 최대 문장 길이 세기 <br>\n",
        "padding 작업을 하는 이유:자연어 처리 과정에서 문장의 길이를 임의로 맞춤으로써 하나의 행렬로 인식해 수월한 작업이 가능하다. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2762afc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2762afc",
        "outputId": "7ada3a74-eb5b-429e-b296-a3c1b7607450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "영어 문장의 최대 길이 : 36\n",
            "스페인어 문장의 최대 길이 : 95\n"
          ]
        }
      ],
      "source": [
        "max_eng_len = max([len(line) for line in lines.eng])\n",
        "max_spa_len = max([len(line) for line in lines.spa])\n",
        "print('영어 문장의 최대 길이 :',max_eng_len)\n",
        "print('스페인어 문장의 최대 길이 :',max_spa_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lKqaPzhqY7Fd",
      "metadata": {
        "id": "lKqaPzhqY7Fd"
      },
      "source": [
        "따라서 영어 데이터 길이는 36, 스페인어 데이터 길이는 91에 맞추어 패딩을 진행한다. <br>\n",
        "pad_sequences 함수를 통해 공란에 0이 대체 되도록 패딩 자동 진행한다. ('post' : 최대 길이에 맞춰줌)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e15227a5",
      "metadata": {
        "id": "e15227a5"
      },
      "outputs": [],
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_eng_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_spa_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_spa_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48f352fa",
      "metadata": {
        "id": "48f352fa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Prx0Q1V5ZPax",
      "metadata": {
        "id": "Prx0Q1V5ZPax"
      },
      "source": [
        "원-핫 인코딩:표현하고 싶은 단어의 인덱스에 1을 부여하고, 다른 인덱스에는 0을 부여하여 단어를 표현한다. <br>케라스에서 지원하는 to_categorical을 통해서 원-핫 인코딩을 진행할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f63b45fd",
      "metadata": {
        "id": "f63b45fd"
      },
      "outputs": [],
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d7bce7",
      "metadata": {
        "id": "b4d7bce7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8b8608",
      "metadata": {
        "id": "4d8b8608"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "#인코더에 입력을 넣으면 내부 상태 리턴\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7zXGvF3D0j5J",
      "metadata": {
        "id": "7zXGvF3D0j5J"
      },
      "source": [
        "state_h: lstm 은닉상태\n",
        "state_c: lstm 셀 상태"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1308d9",
      "metadata": {
        "id": "ed1308d9"
      },
      "outputs": [],
      "source": [
        "decoder_inputs = Input(shape=(None, spa_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "\n",
        "\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "decoder_softmax_layer = Dense(spa_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22620a4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "22620a4c",
        "outputId": "351f1380-081a-4c72-f29d-65e8fdd30634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1250/1250 [==============================] - 922s 731ms/step - loss: 0.6993 - val_loss: 0.7748\n",
            "Epoch 2/40\n",
            "1250/1250 [==============================] - 924s 739ms/step - loss: 0.4980 - val_loss: 0.6763\n",
            "Epoch 3/40\n",
            "1250/1250 [==============================] - 937s 750ms/step - loss: 0.4435 - val_loss: 0.6197\n",
            "Epoch 4/40\n",
            "1250/1250 [==============================] - 913s 730ms/step - loss: 0.4109 - val_loss: 0.5808\n",
            "Epoch 5/40\n",
            "1250/1250 [==============================] - 1030s 824ms/step - loss: 0.3856 - val_loss: 0.5556\n",
            "Epoch 6/40\n",
            "1250/1250 [==============================] - 857s 686ms/step - loss: 0.3668 - val_loss: 0.5341\n",
            "Epoch 7/40\n",
            "1250/1250 [==============================] - 643s 515ms/step - loss: 0.3501 - val_loss: 0.5162\n",
            "Epoch 8/40\n",
            "1250/1250 [==============================] - 654s 523ms/step - loss: 0.3373 - val_loss: 0.4973\n",
            "Epoch 9/40\n",
            "1250/1250 [==============================] - 726s 581ms/step - loss: 0.3270 - val_loss: 0.4846\n",
            "Epoch 10/40\n",
            "1250/1250 [==============================] - 704s 563ms/step - loss: 0.3179 - val_loss: 0.4764\n",
            "Epoch 11/40\n",
            "1250/1250 [==============================] - 714s 571ms/step - loss: 0.3116 - val_loss: 0.4692\n",
            "Epoch 12/40\n",
            "1250/1250 [==============================] - 722s 577ms/step - loss: 0.3045 - val_loss: 0.4604\n",
            "Epoch 13/40\n",
            "1250/1250 [==============================] - 713s 571ms/step - loss: 0.2983 - val_loss: 0.4553\n",
            "Epoch 14/40\n",
            "1250/1250 [==============================] - 711s 569ms/step - loss: 0.2930 - val_loss: 0.4494\n",
            "Epoch 15/40\n",
            "1250/1250 [==============================] - 689s 551ms/step - loss: 0.2879 - val_loss: 0.4419\n",
            "Epoch 16/40\n",
            "1250/1250 [==============================] - 702s 562ms/step - loss: 0.2829 - val_loss: 0.4371\n",
            "Epoch 17/40\n",
            "1250/1250 [==============================] - 724s 579ms/step - loss: 0.2782 - val_loss: 0.4325\n",
            "Epoch 18/40\n",
            "1250/1250 [==============================] - 735s 588ms/step - loss: 0.2740 - val_loss: 0.4297\n",
            "Epoch 19/40\n",
            "1250/1250 [==============================] - 732s 586ms/step - loss: 0.2699 - val_loss: 0.4245\n",
            "Epoch 20/40\n",
            "1250/1250 [==============================] - 753s 603ms/step - loss: 0.2663 - val_loss: 0.4209\n",
            "Epoch 21/40\n",
            "1250/1250 [==============================] - 650s 520ms/step - loss: 0.2630 - val_loss: 0.4173\n",
            "Epoch 22/40\n",
            "1250/1250 [==============================] - 638s 511ms/step - loss: 0.2599 - val_loss: 0.4144\n",
            "Epoch 23/40\n",
            "1250/1250 [==============================] - 10096s 8s/step - loss: 0.2569 - val_loss: 0.4130\n",
            "Epoch 24/40\n",
            "1250/1250 [==============================] - 3784s 3s/step - loss: 0.2542 - val_loss: 0.4107\n",
            "Epoch 25/40\n",
            "1250/1250 [==============================] - 588s 470ms/step - loss: 0.2516 - val_loss: 0.4076\n",
            "Epoch 26/40\n",
            "1250/1250 [==============================] - 721s 577ms/step - loss: 0.2491 - val_loss: 0.4057\n",
            "Epoch 27/40\n",
            "1250/1250 [==============================] - 646s 516ms/step - loss: 0.2467 - val_loss: 0.4036\n",
            "Epoch 28/40\n",
            "1250/1250 [==============================] - 661s 529ms/step - loss: 0.2446 - val_loss: 0.4012\n",
            "Epoch 29/40\n",
            "1250/1250 [==============================] - 710s 568ms/step - loss: 0.2423 - val_loss: 0.3994\n",
            "Epoch 30/40\n",
            "1250/1250 [==============================] - 651s 521ms/step - loss: 0.2403 - val_loss: 0.3982\n",
            "Epoch 31/40\n",
            "1250/1250 [==============================] - 649s 519ms/step - loss: 0.2384 - val_loss: 0.3978\n",
            "Epoch 32/40\n",
            "1250/1250 [==============================] - 644s 515ms/step - loss: 0.2367 - val_loss: 0.3962\n",
            "Epoch 33/40\n",
            "1250/1250 [==============================] - 696s 557ms/step - loss: 0.2349 - val_loss: 0.3943\n",
            "Epoch 34/40\n",
            "1250/1250 [==============================] - 674s 539ms/step - loss: 0.2333 - val_loss: 0.3937\n",
            "Epoch 35/40\n",
            "1250/1250 [==============================] - 722s 578ms/step - loss: 0.2316 - val_loss: 0.3932\n",
            "Epoch 36/40\n",
            "1250/1250 [==============================] - 708s 566ms/step - loss: 0.2301 - val_loss: 0.3915\n",
            "Epoch 37/40\n",
            "1250/1250 [==============================] - 723s 579ms/step - loss: 0.2286 - val_loss: 0.3922\n",
            "Epoch 38/40\n",
            "1250/1250 [==============================] - 705s 564ms/step - loss: 0.2273 - val_loss: 0.3908\n",
            "Epoch 39/40\n",
            "1250/1250 [==============================] - 862s 690ms/step - loss: 0.2259 - val_loss: 0.3901\n",
            "Epoch 40/40\n",
            "1250/1250 [==============================] - 950s 760ms/step - loss: 0.2245 - val_loss: 0.3889\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x29d36b6d910>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=40, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9fe435",
      "metadata": {
        "id": "cd9fe435"
      },
      "outputs": [],
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba3f630e",
      "metadata": {
        "id": "ba3f630e"
      },
      "outputs": [],
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bffa9255",
      "metadata": {
        "id": "bffa9255"
      },
      "outputs": [],
      "source": [
        "index_to_eng = dict((i, char) for char, i in eng_to_index.items())\n",
        "index_to_spa = dict((i, char) for char, i in spa_to_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cdbe1eb",
      "metadata": {
        "id": "6cdbe1eb",
        "outputId": "5834ad0d-335f-4ebf-f323-289e19eeed58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "-----------------------------------\n",
            "입력 문장: Who?\n",
            "정답 문장: \t ¿Quién? \n",
            " \n",
            "번역 문장: \t ¡Qué verde! \n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-----------------------------------\n",
            "입력 문장: I froze.\n",
            "정답 문장: \t Me helé. \n",
            " \n",
            "번역 문장:  Me encanta la comida. \n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-----------------------------------\n",
            "입력 문장: He got angry.\n",
            "정답 문장: \t Él se enfadó. \n",
            " \n",
            "번역 문장:  Él no está aquí. \n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "-----------------------------------\n",
            "입력 문장: I'm not afraid of death.\n",
            "정답 문장: \t No le temo a la muerte. \n",
            " \n",
            "번역 문장:  Nada me estoy muriendo de verdad. \n"
          ]
        }
      ],
      "source": [
        "for seq_index in [11,222,3333,44444]: # 입력 문장의 인덱스\n",
        "  input_seq = encoder_input[seq_index:seq_index+1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장:', lines.eng[seq_index])\n",
        "  print('정답 문장:', lines.spa[seq_index][2:len(lines.spa[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14ef6718",
      "metadata": {
        "id": "14ef6718"
      },
      "source": [
        "제작한 전처리 함수를 포함한 번역기로 업데이트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a86611",
      "metadata": {
        "id": "f5a86611"
      },
      "outputs": [],
      "source": [
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9AQumtnC8OZR",
      "metadata": {
        "id": "9AQumtnC8OZR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import urllib3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8447d5a",
      "metadata": {
        "id": "e8447d5a"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sent):\n",
        "    sent = to_ascii(sent.lower())\n",
        "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
        "    sent = re.sub(r\"[^a-zA-Z!.?¿¡]+\", r\" \", sent)\n",
        "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcfd9cd0",
      "metadata": {
        "id": "fcfd9cd0"
      },
      "outputs": [],
      "source": [
        "def to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "                   if unicodedata.category(c) != 'Mn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h4GhVHbO8B2d",
      "metadata": {
        "id": "h4GhVHbO8B2d",
        "outputId": "2851a8a5-dec3-42cb-8ab3-2f75f6149220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전처리 전 스페인어 문장 : ¡mañana, el árbol será más grande que hoy!\n",
            "전처리 후 스페인어 문장 : ¡manana el arbol sera mas grande que hoy !\n"
          ]
        }
      ],
      "source": [
        "#Ex\n",
        "spa_sent = u'¡mañana, el árbol será más grande que hoy!'\n",
        "print('전처리 전 스페인어 문장 :', spa_sent)\n",
        "print('전처리 후 스페인어 문장 :', preprocess_sentence(spa_sent))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5p3i6BdQ1zq3",
      "metadata": {
        "id": "5p3i6BdQ1zq3"
      },
      "source": [
        "입력 시퀀스에는 시작을 의미하는 <sos> 토큰을, 출력 시퀀스에는 종료를 의미하는 <eos>토큰을 추가한다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tUYYbrWD8WWn",
      "metadata": {
        "id": "tUYYbrWD8WWn"
      },
      "outputs": [],
      "source": [
        "def load_preprocessed_data():\n",
        "  encoder_input, decoder_input, decoder_target = [], [], []\n",
        "\n",
        "  with open(\"C:\\\\Users\\\\82105\\\\Desktop\\\\spa.txt\", \"r\") as lines:\n",
        "    for i, line in enumerate(lines):\n",
        "      eng_line, spa_line, _ = line.strip().split('\\t')\n",
        "\n",
        "      \n",
        "      eng_line = [w for w in preprocess_sentence(eng_line).split()]\n",
        "\n",
        "     \n",
        "      spa_line = preprocess_sentence(spa_line)\n",
        "      spa_line_in = [w for w in (\"<sos> \" + spa_line).split()]\n",
        "      spa_line_out = [w for w in (spa_line + \" <eos>\").split()]\n",
        "\n",
        "      encoder_input.append(eng_line)\n",
        "      decoder_input.append(spa_line_in)\n",
        "      decoder_target.append(spa_line_out)\n",
        "\n",
        "      if i == num_samples - 1:\n",
        "        break\n",
        "\n",
        "  return encoder_input, decoder_input, decoder_target"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1wV62xoUzMSH"
      },
      "id": "1wV62xoUzMSH",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}